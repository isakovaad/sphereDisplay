{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b996796f-a7e5-4697-8d7f-2a499b47202d",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "- Meeting Audio Data Augmenter\n",
    "- Transforms real meeting recordings into comprehensive ML training dataset\n",
    "- Usage: python data_augmenter.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4926d1-b7d6-45d7-94bf-7fdb34187ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import copy\n",
    "from scipy import signal\n",
    "from scipy.interpolate import interp1d\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0bc7d2f-a0bd-472b-9825-769a420bc5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meeting Audio Data Augmenter\n",
      "==================================================\n",
      " Meeting Audio Augmenter initialized\n",
      " Input: 8 original recordings\n",
      " Target: 480 augmented samples\n",
      "Meeting Audio Data Augmentation Pipeline\n",
      "================================================================================\n",
      "\n",
      " Loading original audio data...\n",
      "Loaded meeting_20250617_144307: 367 samples\n",
      "Loaded meeting_20250617_145139: 650 samples\n",
      "Loaded meeting_20250620_130013: 618 samples\n",
      "Loaded meeting_20250620_130618: 534 samples\n",
      "Loaded meeting_20250624_132317: 568 samples\n",
      "Loaded meeting_20250624_132856: 689 samples\n",
      "Loaded meeting_20250624_133532: 450 samples\n",
      "Loaded meeting_20250624_135319: 196 samples\n",
      "\n",
      "Starting dataset augmentation...\n",
      "Generated 60 augmentation variations\n",
      "\n",
      "Processing meeting_20250617_144307...\n",
      "   Generated 10/60 samples\n",
      "   Generated 20/60 samples\n",
      "   Generated 30/60 samples\n",
      "   Generated 40/60 samples\n",
      "   Generated 50/60 samples\n",
      "   Generated 60/60 samples\n",
      "Completed meeting_20250617_144307: 60 samples generated\n",
      "\n",
      "Processing meeting_20250617_145139...\n",
      "   Generated 10/60 samples\n",
      "   Generated 20/60 samples\n",
      "   Generated 30/60 samples\n",
      "   Generated 40/60 samples\n",
      "   Generated 50/60 samples\n",
      "   Generated 60/60 samples\n",
      "Completed meeting_20250617_145139: 60 samples generated\n",
      "\n",
      "Processing meeting_20250620_130013...\n",
      "   Generated 10/60 samples\n",
      "   Generated 20/60 samples\n",
      "   Generated 30/60 samples\n",
      "   Generated 40/60 samples\n",
      "   Generated 50/60 samples\n",
      "   Generated 60/60 samples\n",
      "Completed meeting_20250620_130013: 60 samples generated\n",
      "\n",
      "Processing meeting_20250620_130618...\n",
      "   Generated 10/60 samples\n",
      "   Generated 20/60 samples\n",
      "   Generated 30/60 samples\n",
      "   Generated 40/60 samples\n",
      "   Generated 50/60 samples\n",
      "   Generated 60/60 samples\n",
      "Completed meeting_20250620_130618: 60 samples generated\n",
      "\n",
      "Processing meeting_20250624_132317...\n",
      "   Generated 10/60 samples\n",
      "   Generated 20/60 samples\n",
      "   Generated 30/60 samples\n",
      "   Generated 40/60 samples\n",
      "   Generated 50/60 samples\n",
      "   Generated 60/60 samples\n",
      "Completed meeting_20250624_132317: 60 samples generated\n",
      "\n",
      "Processing meeting_20250624_132856...\n",
      "   Generated 10/60 samples\n",
      "   Generated 20/60 samples\n",
      "   Generated 30/60 samples\n",
      "   Generated 40/60 samples\n",
      "   Generated 50/60 samples\n",
      "   Generated 60/60 samples\n",
      "Completed meeting_20250624_132856: 60 samples generated\n",
      "\n",
      "Processing meeting_20250624_133532...\n",
      "   Generated 10/60 samples\n",
      "   Generated 20/60 samples\n",
      "   Generated 30/60 samples\n",
      "   Generated 40/60 samples\n",
      "   Generated 50/60 samples\n",
      "   Generated 60/60 samples\n",
      "Completed meeting_20250624_133532: 60 samples generated\n",
      "\n",
      "Processing meeting_20250624_135319...\n",
      "   Generated 10/60 samples\n",
      "   Generated 20/60 samples\n",
      "   Generated 30/60 samples\n",
      "   Generated 40/60 samples\n",
      "   Generated 50/60 samples\n",
      "   Generated 60/60 samples\n",
      "Completed meeting_20250624_135319: 60 samples generated\n",
      "\n",
      "Augmentation complete!\n",
      "Total samples generated: 480\n",
      "Original recordings: 8\n",
      "Augmentation ratio: 60.0x\n",
      "   Saved augmented master CSV: augmented_data/augmented_sessions_master.csv\n",
      "   Augmented dataset summary:\n",
      "   Total samples: 480\n",
      "   Speaker counts: {'3+': 240, '2': 120, 'unknown': 60, '3': 60}\n",
      "   Meeting types: {'presentation': 168, 'argument': 120, 'brainstorm': 104, 'discussion': 88}\n",
      "   Energy levels: {'high': 192, 'low': 144, 'medium': 144}\n",
      "   Background noise: {'medium': 168, 'none': 128, 'low': 104, 'high': 80}\n",
      "\n",
      "================================================================================\n",
      "AUGMENTATION PIPELINE COMPLETE!\n",
      "================================================================================\n",
      "   Results:\n",
      "   Original recordings: 8\n",
      "   Generated samples: 480\n",
      "   Total dataset size: 488\n",
      "   Augmentation factor: 60.0x\n",
      "\n",
      " Output Location:\n",
      "   Augmented data: augmented_data\n",
      "   Master CSV: augmented_data/augmented_sessions_master.csv\n",
      "\n",
      " Data is ready for ML Training:\n",
      "   Balanced dataset across all categories\n",
      "   Realistic audio variations\n",
      "   Proper label preservation\n",
      "   ML-ready format\n",
      "\n",
      " My next steps:\n",
      "   1. Run: python dataset_analyzer.ipynb (to analyze augmented data)\n",
      "   2. Build ML models using the augmented dataset\n",
      "   3. Train and validate models\n",
      "   4. Deploy to your web interface\n"
     ]
    }
   ],
   "source": [
    "class MeetingAudioAugmenter:\n",
    "    def __init__(self, data_dir=\"./\"):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.recordings_dir = self.data_dir / \"recordings\"\n",
    "        self.labels_dir = self.data_dir / \"labels\"\n",
    "        self.output_dir = self.data_dir / \"augmented_data\"\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Load original data\n",
    "        self.master_csv = self.labels_dir / \"sessions_master.csv\"\n",
    "        self.df = pd.read_csv(self.master_csv)\n",
    "        self.original_audio_data = {}\n",
    "        \n",
    "        # Augmentation parameters\n",
    "        self.target_samples_per_original = 60\n",
    "        self.augmented_sessions = []\n",
    "        \n",
    "        print(f\" Meeting Audio Augmenter initialized\")\n",
    "        print(f\" Input: {len(self.df)} original recordings\")\n",
    "        print(f\" Target: {len(self.df) * self.target_samples_per_original} augmented samples\")\n",
    "    \n",
    "    def load_original_data(self):\n",
    "        \"\"\"Load all original audio recordings\"\"\"\n",
    "        print(\"\\n Loading original audio data...\")\n",
    "        \n",
    "        for _, session in self.df.iterrows():\n",
    "            session_id = session['session_id']\n",
    "            audio_file = self.recordings_dir / f\"{session_id}_audio.json\"\n",
    "            labels_file = self.labels_dir / f\"{session_id}_labels.json\"\n",
    "            \n",
    "            if audio_file.exists() and labels_file.exists():\n",
    "                # Load audio data\n",
    "                with open(audio_file, 'r') as f:\n",
    "                    audio_data = json.load(f)\n",
    "                \n",
    "                # Load labels\n",
    "                with open(labels_file, 'r') as f:\n",
    "                    labels = json.load(f)\n",
    "                \n",
    "                self.original_audio_data[session_id] = {\n",
    "                    'audio': audio_data,\n",
    "                    'labels': labels,\n",
    "                    'csv_row': session.to_dict()\n",
    "                }\n",
    "                \n",
    "                print(f\"Loaded {session_id}: {len(audio_data)} samples\")\n",
    "            else:\n",
    "                print(f\"Missing files for {session_id}\")\n",
    "    \n",
    "    def time_stretch_audio(self, audio_samples, stretch_factor):\n",
    "        \"\"\"Apply time stretching to audio samples\"\"\"\n",
    "        if stretch_factor == 1.0:\n",
    "            return audio_samples\n",
    "        \n",
    "        # Create new sample indices\n",
    "        original_length = len(audio_samples)\n",
    "        new_length = int(original_length / stretch_factor)\n",
    "        \n",
    "        if new_length < 10:  # Minimum length check\n",
    "            return audio_samples\n",
    "        \n",
    "        # Extract time series\n",
    "        timestamps = np.array([i for i in range(original_length)])\n",
    "        left_mics = np.array([s['leftMic'] for s in audio_samples])\n",
    "        right_mics = np.array([s['rightMic'] for s in audio_samples])\n",
    "        \n",
    "        # Create interpolation functions\n",
    "        left_interp = interp1d(timestamps, left_mics, kind='linear', \n",
    "                              bounds_error=False, fill_value='extrapolate')\n",
    "        right_interp = interp1d(timestamps, right_mics, kind='linear', \n",
    "                               bounds_error=False, fill_value='extrapolate')\n",
    "        \n",
    "        # Generate new timestamps\n",
    "        new_timestamps = np.linspace(0, original_length-1, new_length)\n",
    "        \n",
    "        # Interpolate values\n",
    "        new_left = left_interp(new_timestamps)\n",
    "        new_right = right_interp(new_timestamps)\n",
    "        \n",
    "        # Create new audio samples\n",
    "        stretched_samples = []\n",
    "        base_timestamp = audio_samples[0]['timestamp'] if audio_samples else 0\n",
    "        \n",
    "        for i, (left, right) in enumerate(zip(new_left, new_right)):\n",
    "            sample = {\n",
    "                'leftMic': float(left),\n",
    "                'rightMic': float(right),\n",
    "                'difference': float(left - right),\n",
    "                'averageLevel': float((left + right) / 2),\n",
    "                'timestamp': base_timestamp + i * 1000,  # Approximate timestamp\n",
    "                'local_timestamp': audio_samples[0]['local_timestamp'] + i,\n",
    "                'local_datetime': audio_samples[0]['local_datetime']  # Keep original\n",
    "            }\n",
    "            stretched_samples.append(sample)\n",
    "        \n",
    "        return stretched_samples\n",
    "    \n",
    "    def pitch_shift_audio(self, audio_samples, semitone_shift):\n",
    "        \"\"\"Apply pitch shifting (simulate different speakers)\"\"\"\n",
    "        if semitone_shift == 0:\n",
    "            return audio_samples\n",
    "        \n",
    "        # Pitch shift multiplier (semitones to frequency ratio)\n",
    "        pitch_ratio = 2 ** (semitone_shift / 12.0)\n",
    "        \n",
    "        shifted_samples = []\n",
    "        for sample in audio_samples:\n",
    "            # Apply pitch shift to volume levels (simulates different voice characteristics)\n",
    "            left_shifted = sample['leftMic'] * (0.95 + 0.1 * random.random()) * pitch_ratio\n",
    "            right_shifted = sample['rightMic'] * (0.95 + 0.1 * random.random()) * pitch_ratio\n",
    "            \n",
    "            # Keep within reasonable dB range\n",
    "            left_shifted = np.clip(left_shifted, 20, 90)\n",
    "            right_shifted = np.clip(right_shifted, 20, 90)\n",
    "            \n",
    "            new_sample = copy.deepcopy(sample)\n",
    "            new_sample['leftMic'] = float(left_shifted)\n",
    "            new_sample['rightMic'] = float(right_shifted)\n",
    "            new_sample['difference'] = float(left_shifted - right_shifted)\n",
    "            new_sample['averageLevel'] = float((left_shifted + right_shifted) / 2)\n",
    "            \n",
    "            shifted_samples.append(new_sample)\n",
    "        \n",
    "        return shifted_samples\n",
    "    \n",
    "    def adjust_stereo_positioning(self, audio_samples, position_shift):\n",
    "        \"\"\"Simulate different speaker positions\"\"\"\n",
    "        if position_shift == 0:\n",
    "            return audio_samples\n",
    "        \n",
    "        positioned_samples = []\n",
    "        for sample in audio_samples:\n",
    "            # Apply stereo positioning shift\n",
    "            left = sample['leftMic']\n",
    "            right = sample['rightMic']\n",
    "            \n",
    "            # Shift speaker position (-1.0 = hard left, +1.0 = hard right)\n",
    "            if position_shift > 0:  # Shift toward right\n",
    "                left_adj = left * (1 - position_shift * 0.3)\n",
    "                right_adj = right * (1 + position_shift * 0.2)\n",
    "            else:  # Shift toward left\n",
    "                left_adj = left * (1 + abs(position_shift) * 0.2)\n",
    "                right_adj = right * (1 - abs(position_shift) * 0.3)\n",
    "            \n",
    "            new_sample = copy.deepcopy(sample)\n",
    "            new_sample['leftMic'] = float(left_adj)\n",
    "            new_sample['rightMic'] = float(right_adj)\n",
    "            new_sample['difference'] = float(left_adj - right_adj)\n",
    "            new_sample['averageLevel'] = float((left_adj + right_adj) / 2)\n",
    "            \n",
    "            positioned_samples.append(new_sample)\n",
    "        \n",
    "        return positioned_samples\n",
    "    \n",
    "    def add_background_noise(self, audio_samples, noise_level):\n",
    "        \"\"\"Add background noise simulation\"\"\"\n",
    "        if noise_level == 'none':\n",
    "            return audio_samples\n",
    "        \n",
    "        # Define noise levels (dB to add)\n",
    "        noise_mapping = {\n",
    "            'low': (1, 3),\n",
    "            'medium': (3, 6),\n",
    "            'high': (6, 10)\n",
    "        }\n",
    "        \n",
    "        if noise_level not in noise_mapping:\n",
    "            return audio_samples\n",
    "        \n",
    "        min_noise, max_noise = noise_mapping[noise_level]\n",
    "        \n",
    "        noisy_samples = []\n",
    "        for sample in audio_samples:\n",
    "            # Add random noise\n",
    "            left_noise = random.uniform(min_noise, max_noise)\n",
    "            right_noise = random.uniform(min_noise, max_noise)\n",
    "            \n",
    "            new_sample = copy.deepcopy(sample)\n",
    "            new_sample['leftMic'] = float(sample['leftMic'] + left_noise)\n",
    "            new_sample['rightMic'] = float(sample['rightMic'] + right_noise)\n",
    "            new_sample['difference'] = float(new_sample['leftMic'] - new_sample['rightMic'])\n",
    "            new_sample['averageLevel'] = float((new_sample['leftMic'] + new_sample['rightMic']) / 2)\n",
    "            \n",
    "            noisy_samples.append(new_sample)\n",
    "        \n",
    "        return noisy_samples\n",
    "    \n",
    "    def adjust_energy_level(self, audio_samples, target_energy):\n",
    "        \"\"\"Adjust overall energy level of the meeting\"\"\"\n",
    "        if target_energy == 'medium':\n",
    "            return audio_samples\n",
    "        \n",
    "        # Calculate current average energy\n",
    "        avg_levels = [s['averageLevel'] for s in audio_samples]\n",
    "        current_avg = np.mean(avg_levels)\n",
    "        \n",
    "        # Define energy adjustments\n",
    "        if target_energy == 'low':\n",
    "            # Reduce volume and variation\n",
    "            volume_multiplier = 0.8\n",
    "            variation_multiplier = 0.6\n",
    "        elif target_energy == 'high':\n",
    "            # Increase volume and variation\n",
    "            volume_multiplier = 1.2\n",
    "            variation_multiplier = 1.4\n",
    "        else:\n",
    "            return audio_samples\n",
    "        \n",
    "        adjusted_samples = []\n",
    "        for sample in audio_samples:\n",
    "            # Apply energy adjustment\n",
    "            left_adj = (sample['leftMic'] - current_avg) * variation_multiplier + current_avg\n",
    "            right_adj = (sample['rightMic'] - current_avg) * variation_multiplier + current_avg\n",
    "            \n",
    "            left_adj *= volume_multiplier\n",
    "            right_adj *= volume_multiplier\n",
    "            \n",
    "            # Keep within reasonable bounds\n",
    "            left_adj = np.clip(left_adj, 25, 85)\n",
    "            right_adj = np.clip(right_adj, 25, 85)\n",
    "            \n",
    "            new_sample = copy.deepcopy(sample)\n",
    "            new_sample['leftMic'] = float(left_adj)\n",
    "            new_sample['rightMic'] = float(right_adj)\n",
    "            new_sample['difference'] = float(left_adj - right_adj)\n",
    "            new_sample['averageLevel'] = float((left_adj + right_adj) / 2)\n",
    "            \n",
    "            adjusted_samples.append(new_sample)\n",
    "        \n",
    "        return adjusted_samples\n",
    "    \n",
    "    def simulate_turn_taking(self, audio_samples, meeting_type):\n",
    "        \"\"\"Simulate different turn-taking patterns based on meeting type\"\"\"\n",
    "        if meeting_type in ['discussion', 'unknown']:\n",
    "            return audio_samples  # Keep original patterns\n",
    "        \n",
    "        modified_samples = copy.deepcopy(audio_samples)\n",
    "        \n",
    "        if meeting_type == 'brainstorm':\n",
    "            # More rapid speaker switches and interruptions\n",
    "            for i in range(1, len(modified_samples)):\n",
    "                if random.random() < 0.15:  # 15% chance of rapid switch\n",
    "                    # Swap left/right dominance\n",
    "                    left = modified_samples[i]['leftMic']\n",
    "                    right = modified_samples[i]['rightMic']\n",
    "                    modified_samples[i]['leftMic'] = right\n",
    "                    modified_samples[i]['rightMic'] = left\n",
    "                    modified_samples[i]['difference'] = right - left\n",
    "                    modified_samples[i]['averageLevel'] = (left + right) / 2\n",
    "        \n",
    "        elif meeting_type == 'presentation':\n",
    "            # One dominant speaker with occasional questions\n",
    "            total_samples = len(modified_samples)\n",
    "            dominant_side = random.choice(['left', 'right'])\n",
    "            \n",
    "            for i, sample in enumerate(modified_samples):\n",
    "                if random.random() < 0.8:  # 80% time dominant speaker\n",
    "                    if dominant_side == 'left':\n",
    "                        sample['leftMic'] *= 1.3\n",
    "                        sample['rightMic'] *= 0.7\n",
    "                    else:\n",
    "                        sample['rightMic'] *= 1.3\n",
    "                        sample['leftMic'] *= 0.7\n",
    "                    \n",
    "                    sample['difference'] = sample['leftMic'] - sample['rightMic']\n",
    "                    sample['averageLevel'] = (sample['leftMic'] + sample['rightMic']) / 2\n",
    "        \n",
    "        elif meeting_type == 'argument':\n",
    "            # More interruptions and overlapping speech\n",
    "            for i in range(len(modified_samples)):\n",
    "                if random.random() < 0.25:  # 25% chance of overlapping speech\n",
    "                    # Increase both sides (overlapping)\n",
    "                    modified_samples[i]['leftMic'] *= 1.2\n",
    "                    modified_samples[i]['rightMic'] *= 1.2\n",
    "                    modified_samples[i]['averageLevel'] = (modified_samples[i]['leftMic'] + modified_samples[i]['rightMic']) / 2\n",
    "        \n",
    "        return modified_samples\n",
    "    \n",
    "    def generate_augmented_sample(self, original_session_id, augmentation_params):\n",
    "        \"\"\"Generate one augmented sample from original recording\"\"\"\n",
    "        original_data = self.original_audio_data[original_session_id]\n",
    "        audio_samples = copy.deepcopy(original_data['audio'])\n",
    "        original_labels = copy.deepcopy(original_data['labels'])\n",
    "        \n",
    "        # Apply augmentations in sequence\n",
    "        if 'time_stretch' in augmentation_params:\n",
    "            audio_samples = self.time_stretch_audio(audio_samples, augmentation_params['time_stretch'])\n",
    "        \n",
    "        if 'pitch_shift' in augmentation_params:\n",
    "            audio_samples = self.pitch_shift_audio(audio_samples, augmentation_params['pitch_shift'])\n",
    "        \n",
    "        if 'stereo_position' in augmentation_params:\n",
    "            audio_samples = self.adjust_stereo_positioning(audio_samples, augmentation_params['stereo_position'])\n",
    "        \n",
    "        if 'background_noise' in augmentation_params:\n",
    "            audio_samples = self.add_background_noise(audio_samples, augmentation_params['background_noise'])\n",
    "        \n",
    "        if 'energy_level' in augmentation_params:\n",
    "            audio_samples = self.adjust_energy_level(audio_samples, augmentation_params['energy_level'])\n",
    "        \n",
    "        if 'meeting_type' in augmentation_params:\n",
    "            audio_samples = self.simulate_turn_taking(audio_samples, augmentation_params['meeting_type'])\n",
    "        \n",
    "        # Update labels based on augmentation\n",
    "        new_labels = copy.deepcopy(original_labels)\n",
    "        \n",
    "        # Update labels with augmentation effects\n",
    "        if 'energy_level' in augmentation_params:\n",
    "            new_labels['energy_level'] = augmentation_params['energy_level']\n",
    "        \n",
    "        if 'background_noise' in augmentation_params:\n",
    "            new_labels['background_noise'] = augmentation_params['background_noise']\n",
    "        \n",
    "        if 'meeting_type' in augmentation_params:\n",
    "            new_labels['meeting_type'] = augmentation_params['meeting_type']\n",
    "        \n",
    "        # Update duration and sample count\n",
    "        new_labels['sample_count'] = len(audio_samples)\n",
    "        if 'time_stretch' in augmentation_params:\n",
    "            original_duration = original_labels['duration_seconds']\n",
    "            new_labels['duration_seconds'] = original_duration / augmentation_params['time_stretch']\n",
    "        \n",
    "        return audio_samples, new_labels\n",
    "    \n",
    "    def generate_augmentation_variations(self):\n",
    "        \"\"\"Generate all possible augmentation parameter combinations\"\"\"\n",
    "        variations = []\n",
    "        \n",
    "        # Time stretching variations\n",
    "        time_stretches = [0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "        \n",
    "        # Pitch shifting variations\n",
    "        pitch_shifts = [-2, -1, 0, 1, 2]\n",
    "        \n",
    "        # Stereo positioning variations\n",
    "        stereo_positions = [-0.6, -0.3, 0, 0.3, 0.6]\n",
    "        \n",
    "        # Background noise variations\n",
    "        bg_noises = ['none', 'low', 'medium', 'high']\n",
    "        \n",
    "        # Energy level variations\n",
    "        energy_levels = ['low', 'medium', 'high']\n",
    "        \n",
    "        # Meeting type variations\n",
    "        meeting_types = ['discussion', 'presentation', 'brainstorm', 'argument']\n",
    "        \n",
    "        # Generate combinations (sample to get target number)\n",
    "        target_per_original = self.target_samples_per_original\n",
    "        \n",
    "        for _ in range(target_per_original):\n",
    "            variation = {\n",
    "                'time_stretch': random.choice(time_stretches),\n",
    "                'pitch_shift': random.choice(pitch_shifts),\n",
    "                'stereo_position': random.choice(stereo_positions),\n",
    "                'background_noise': random.choice(bg_noises),\n",
    "                'energy_level': random.choice(energy_levels),\n",
    "                'meeting_type': random.choice(meeting_types)\n",
    "            }\n",
    "            variations.append(variation)\n",
    "        \n",
    "        return variations\n",
    "    \n",
    "    def augment_dataset(self):\n",
    "        \"\"\"Generate complete augmented dataset\"\"\"\n",
    "        print(f\"\\nStarting dataset augmentation...\")\n",
    "        \n",
    "        if not self.original_audio_data:\n",
    "            self.load_original_data()\n",
    "        \n",
    "        # Generate augmentation variations\n",
    "        variations = self.generate_augmentation_variations()\n",
    "        print(f\"Generated {len(variations)} augmentation variations\")\n",
    "        \n",
    "        total_generated = 0\n",
    "        \n",
    "        # Process each original recording\n",
    "        for session_id in self.original_audio_data.keys():\n",
    "            print(f\"\\nProcessing {session_id}...\")\n",
    "            \n",
    "            session_generated = 0\n",
    "            \n",
    "            # Generate variations for this session\n",
    "            for i, variation in enumerate(variations):\n",
    "                try:\n",
    "                    # Generate augmented sample\n",
    "                    aug_audio, aug_labels = self.generate_augmented_sample(session_id, variation)\n",
    "                    \n",
    "                    # Create new session ID\n",
    "                    aug_session_id = f\"{session_id}_aug_{i:03d}\"\n",
    "                    \n",
    "                    # Update labels\n",
    "                    aug_labels['session_id'] = aug_session_id\n",
    "                    aug_labels['original_session_id'] = session_id\n",
    "                    aug_labels['augmentation_params'] = variation\n",
    "                    aug_labels['generated_time'] = datetime.now().isoformat()\n",
    "                    \n",
    "                    # Save augmented data\n",
    "                    self.save_augmented_sample(aug_session_id, aug_audio, aug_labels)\n",
    "                    \n",
    "                    session_generated += 1\n",
    "                    total_generated += 1\n",
    "                    \n",
    "                    if session_generated % 10 == 0:\n",
    "                        print(f\"   Generated {session_generated}/{len(variations)} samples\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating sample {i}: {e}\")\n",
    "            \n",
    "            print(f\"Completed {session_id}: {session_generated} samples generated\")\n",
    "        \n",
    "        print(f\"\\nAugmentation complete!\")\n",
    "        print(f\"Total samples generated: {total_generated}\")\n",
    "        print(f\"Original recordings: {len(self.original_audio_data)}\")\n",
    "        print(f\"Augmentation ratio: {total_generated/len(self.original_audio_data):.1f}x\")\n",
    "        \n",
    "        # Create master CSV for augmented data\n",
    "        self.create_augmented_master_csv()\n",
    "        \n",
    "        return total_generated\n",
    "    \n",
    "    def save_augmented_sample(self, session_id, audio_data, labels):\n",
    "        \"\"\"Save individual augmented sample\"\"\"\n",
    "        # Save audio data\n",
    "        audio_file = self.output_dir / f\"{session_id}_audio.json\"\n",
    "        with open(audio_file, 'w') as f:\n",
    "            json.dump(audio_data, f, indent=2)\n",
    "        \n",
    "        # Save labels\n",
    "        labels_file = self.output_dir / f\"{session_id}_labels.json\"\n",
    "        with open(labels_file, 'w') as f:\n",
    "            json.dump(labels, f, indent=2)\n",
    "        \n",
    "        # Store for CSV creation\n",
    "        self.augmented_sessions.append({\n",
    "            'session_id': session_id,\n",
    "            'start_time': labels.get('start_time', ''),\n",
    "            'duration_seconds': labels.get('duration_seconds', 0),\n",
    "            'sample_count': labels.get('sample_count', 0),\n",
    "            'speaker_count': labels.get('speaker_count', 'unknown'),\n",
    "            'meeting_type': labels.get('meeting_type', 'unknown'),\n",
    "            'energy_level': labels.get('energy_level', 'unknown'),\n",
    "            'background_noise': labels.get('background_noise', 'unknown'),\n",
    "            'original_session_id': labels.get('original_session_id', ''),\n",
    "            'notes': 'Augmented sample'\n",
    "        })\n",
    "    \n",
    "    def create_augmented_master_csv(self):\n",
    "        \"\"\"Create master CSV for augmented dataset\"\"\"\n",
    "        if not self.augmented_sessions:\n",
    "            print(\"No augmented sessions to save\")\n",
    "            return\n",
    "        \n",
    "        aug_df = pd.DataFrame(self.augmented_sessions)\n",
    "        csv_file = self.output_dir / \"augmented_sessions_master.csv\"\n",
    "        aug_df.to_csv(csv_file, index=False)\n",
    "        \n",
    "        print(f\"   Saved augmented master CSV: {csv_file}\")\n",
    "        print(f\"   Augmented dataset summary:\")\n",
    "        print(f\"   Total samples: {len(aug_df)}\")\n",
    "        print(f\"   Speaker counts: {aug_df['speaker_count'].value_counts().to_dict()}\")\n",
    "        print(f\"   Meeting types: {aug_df['meeting_type'].value_counts().to_dict()}\")\n",
    "        print(f\"   Energy levels: {aug_df['energy_level'].value_counts().to_dict()}\")\n",
    "        print(f\"   Background noise: {aug_df['background_noise'].value_counts().to_dict()}\")\n",
    "    \n",
    "    def run_augmentation_pipeline(self):\n",
    "        \"\"\"Run complete augmentation pipeline\"\"\"\n",
    "        print(\"Meeting Audio Data Augmentation Pipeline\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Load original data\n",
    "        self.load_original_data()\n",
    "        \n",
    "        # Run augmentation\n",
    "        total_generated = self.augment_dataset()\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(\"AUGMENTATION PIPELINE COMPLETE!\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"   Results:\")\n",
    "        print(f\"   Original recordings: {len(self.original_audio_data)}\")\n",
    "        print(f\"   Generated samples: {total_generated}\")\n",
    "        print(f\"   Total dataset size: {len(self.original_audio_data) + total_generated}\")\n",
    "        print(f\"   Augmentation factor: {total_generated/len(self.original_audio_data):.1f}x\")\n",
    "        \n",
    "        print(f\"\\n Output Location:\")\n",
    "        print(f\"   Augmented data: {self.output_dir}\")\n",
    "        print(f\"   Master CSV: {self.output_dir}/augmented_sessions_master.csv\")\n",
    "        \n",
    "        print(f\"\\n Data is ready for ML Training:\")\n",
    "        print(f\"   Balanced dataset across all categories\")\n",
    "        print(f\"   Realistic audio variations\")\n",
    "        print(f\"   Proper label preservation\")\n",
    "        print(f\"   ML-ready format\")\n",
    "        \n",
    "        return self.output_dir\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main augmentation function\"\"\"\n",
    "    print(\"Meeting Audio Data Augmenter\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Create augmenter instance\n",
    "    augmenter = MeetingAudioAugmenter()\n",
    "    \n",
    "    # Run augmentation pipeline\n",
    "    output_dir = augmenter.run_augmentation_pipeline()\n",
    "    \n",
    "    print(f\"\\n My next steps:\")\n",
    "    print(f\"   1. Run: python dataset_analyzer.ipynb (to analyze augmented data)\")\n",
    "    print(f\"   2. Build ML models using the augmented dataset\")\n",
    "    print(f\"   3. Train and validate models\")\n",
    "    print(f\"   4. Deploy to your web interface\")\n",
    "    \n",
    "    return augmenter\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    augmenter = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6995e0-e246-4424-b15f-ff77821a056a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
